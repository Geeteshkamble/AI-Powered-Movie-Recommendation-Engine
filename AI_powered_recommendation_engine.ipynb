{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymuiMARsbAFg",
        "outputId": "2d4be71a-e6d4-47b3-d352-9758c4ad8cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!echo '{\"username\":\"beastgeetesh\",\"key\":\"d18522b72211e47a429fde103d117a6b\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os"
      ],
      "metadata": {
        "id": "Q1YvQ8w2bdMf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"prajitdatta/movielens-100k-dataset\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-e-9HfaccW4",
        "outputId": "1b3d6e5b-02ec-4395-815d-f236cc8147a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/prajitdatta/movielens-100k-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.77M/4.77M [00:01<00:00, 3.68MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/prajitdatta/movielens-100k-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List files in the downloaded directory\n",
        "print(\"Files in dataset directory:\", os.listdir(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNz4YVEjcd2D",
        "outputId": "01a388c8-24f8-438e-b961-2d9ed0a3659f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in dataset directory: ['ml-100k']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "q-bpVGSgcgt_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ratings and movies data\n",
        "# Replace 'u.data' and 'u.item' with the exact file names observed in the output above\n",
        "ratings = pd.read_csv(os.path.join(path, \"/content/u.data\"), sep='\\t', names=['userId', 'movieId', 'rating', 'timestamp'])\n",
        "movies = pd.read_csv(os.path.join(path, \"/content/u.item\"), sep='|', encoding='latin-1', names=['movieId', 'title'], usecols=[0, 1])"
      ],
      "metadata": {
        "id": "uGPHfSvocjVi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows to confirm loading\n",
        "print(ratings.head())\n",
        "print(movies.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEPOwQqSc5of",
        "outputId": "24e087b7-1d3b-4d95-d06e-3e7f4c05d444"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating  timestamp\n",
            "0     196      242       3  881250949\n",
            "1     186      302       3  891717742\n",
            "2      22      377       1  878887116\n",
            "3     244       51       2  880606923\n",
            "4     166      346       1  886397596\n",
            "   movieId              title\n",
            "0        1   Toy Story (1995)\n",
            "1        2   GoldenEye (1995)\n",
            "2        3  Four Rooms (1995)\n",
            "3        4  Get Shorty (1995)\n",
            "4        5     Copycat (1995)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns if any\n",
        "ratings = ratings[['userId', 'movieId', 'rating']]"
      ],
      "metadata": {
        "id": "2vu-mC6fc7c6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEekBBq4c90T",
        "outputId": "45454f96-b2da-42bf-c3f4-a01280f8ad89"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357279 sha256=8b23c9d72e5ab41eb3e1f49e84b8794f87da17191cc1b44a1bbd630f53df01b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy"
      ],
      "metadata": {
        "id": "Va7qDHkYdCcw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Reader for the Surprise library\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(ratings, reader)"
      ],
      "metadata": {
        "id": "teGKm05_demk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and testing\n",
        "trainset, testset = train_test_split(data, test_size=0.25)"
      ],
      "metadata": {
        "id": "5U9Ol829dgZc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train the SVD model\n",
        "model = SVD()\n",
        "model.fit(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOKm-LfEdhzk",
        "outputId": "a8c19323-3cd3-476c-8d63-8522869b3189"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7cd1e13ee890>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "predictions = model.test(testset)\n",
        "print(\"RMSE:\", accuracy.rmse(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G1e3Wn3djcr",
        "outputId": "14439ebc-e0d4-4bbe-a277-02546d9cee3f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.9480\n",
            "RMSE: 0.9480290445870658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(user_id, model, movies, ratings, n=10):\n",
        "    # Get movies the user has rated\n",
        "    rated_movie_ids = ratings[ratings['userId'] == user_id]['movieId'].tolist()\n",
        "\n",
        "    # Filter out movies the user has already rated\n",
        "    unrated_movies = movies[~movies['movieId'].isin(rated_movie_ids)]\n",
        "\n",
        "    # Predict ratings for unrated movies\n",
        "    predictions = [model.predict(user_id, movie_id) for movie_id in unrated_movies['movieId']]\n",
        "\n",
        "    # Sort by estimated rating\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "\n",
        "    # Top N recommendations\n",
        "    top_recommendations = predictions[:n]\n",
        "    recommended_movie_ids = [pred.iid for pred in top_recommendations]\n",
        "    recommended_movies = movies[movies['movieId'].isin(recommended_movie_ids)]\n",
        "\n",
        "    return recommended_movies\n",
        "\n",
        "# Get recommendations for user_id=1\n",
        "recommendations = get_recommendations(user_id=1, model=model, movies=movies, ratings=ratings)\n",
        "print(recommendations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZjOPzHEdomc",
        "outputId": "42bcf28b-7391-4797-b0bd-738d1ca7b7b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      movieId                                   title\n",
            "275       276                Leaving Las Vegas (1995)\n",
            "284       285                   Secrets & Lies (1996)\n",
            "356       357  One Flew Over the Cuckoo's Nest (1975)\n",
            "407       408                   Close Shave, A (1995)\n",
            "482       483                       Casablanca (1942)\n",
            "527       528              Killing Fields, The (1984)\n",
            "646       647                              Ran (1985)\n",
            "655       656                                M (1931)\n",
            "922       923            Raise the Red Lantern (1991)\n",
            "1006     1007              Waiting for Guffman (1996)\n"
          ]
        }
      ]
    }
  ]
}